{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OBG2S72KFY9k"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17109,"status":"ok","timestamp":1724942015820,"user":{"displayName":"이예진","userId":"01655535066716294147"},"user_tz":-540},"id":"a1i55kJm8F_l","outputId":"30bc2f40-38b2-4a3f-a31c-09ae8ae1d610"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3782,"status":"ok","timestamp":1724911483162,"user":{"displayName":"Entourage_Team2","userId":"16076991921669842388"},"user_tz":-540},"id":"LMI-bmNmIu7R","outputId":"57fb6f45-b722-4704-bd49-65e42ed87731"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.2.83-py3-none-any.whl.metadata (41 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.5-py3-none-any.whl.metadata (8.9 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Downloading ultralytics-8.2.83-py3-none-any.whl (871 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m871.6/871.6 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.5-py3-none-any.whl (25 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.2.83 ultralytics-thop-2.0.5\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53591,"status":"ok","timestamp":1724917544659,"user":{"displayName":"Entourage_Team2","userId":"16076991921669842388"},"user_tz":-540},"id":"68QMcPvX3XPw","outputId":"20ed391d-8250-4cdd-e86c-7cbdf26dadca"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n","YOLOv5 🚀 2024-8-29 Python-3.10.12 torch-2.4.0+cu121 CPU\n","\n","Fusing layers... \n","YOLOv5m summary: 212 layers, 20885262 parameters, 0 gradients, 48.0 GFLOPs\n","Adding AutoShape... \n","/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with amp.autocast(autocast):\n"]}],"source":["import torch\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","from torchvision.models import DenseNet201_Weights, VGG19_Weights\n","import json\n","\n","\n","# YOLOv5 모델 로드\n","yolo_model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/지우님/yolo_연결/team2_yolov5m_100.pt')\n","yolo_model.imgsz = 416\n","yolo_model.conf = 0.3\n","yolo_model.iou = 0.5\n","yolo_model.agnostic = True\n","yolo_model.stride = 1\n","yolo_model.max_det = 1000\n","yolo_model.line_thickness = 2\n","\n","# 데이터 전처리\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # ResNet50의 입력 크기에 맞게 조정\n","    transforms.ToTensor(),  # 텐서로 변환\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 정규화\n","])\n","\n","# 이미지 로드 및 RGB 변환\n","img_path = '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/지우님/yolo_연결/b.jpeg'\n","img = cv2.imread(img_path)\n","image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","# YOLOv5 모델을 사용하여 탐지\n","results = yolo_model(image_rgb)\n","\n","# 자르기\n","def cropped_img(annotation, resnet_model, results, model_class_id):\n","    detection_data = results.xyxy[0].cpu().numpy()  # YOLOv5의 탐지 결과 추출\n","    json_results = []\n","    # 클래스별로 최대 신뢰도를 추적하기 위한 변수\n","    max_confidence = -1\n","    best_box = None\n","    for *box, conf, cls in detection_data:\n","        class_id = int(cls)\n","        if class_id == model_class_id:\n","            if conf > max_confidence:  # 더 높은 신뢰도일 경우 갱신\n","                max_confidence = conf\n","                best_box = box\n","    if best_box is not None:\n","        x1, y1, x2, y2 = map(int, best_box)\n","        # 바운딩 박스 영역을 자르기\n","        cropped_img = img[y1:y2, x1:x2]\n","        # OpenCV 이미지를 PIL 이미지로 변환\n","        cropped_img_pil = Image.fromarray(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))\n","        # 이미지 전처리\n","        input_tensor = transform(cropped_img_pil).unsqueeze(0).to(device)\n","        # 모델에 이미지 입력하여 예측\n","        with torch.no_grad():\n","            prediction = resnet_model(input_tensor)\n","            predicted_class = torch.argmax(prediction, dim=1).item()\n","        # 결과를 JSON 포맷으로 저장\n","        json_results.append({\n","            \"class\": annotation,\n","            \"predicted_class\": predicted_class\n","        })\n","    return json_results\n","\n","##########################################################################################\n","# 클래스 ID와 해당 모델 매핑\n","model_class_id_map = {\n","    'pigmentation_forehead': 1,  # 이마\n","    'pigmentation_cheek_l': 5,   # 왼쪽 볼\n","    'pigmentation_cheek_r': 6,   # 오른쪽 볼\n","    'wrinkle_perocular_r' : 4,   # 오른쪽 눈가\n","    'wrinkle_perocular_l' : 3,    # 왼쪽 눈가\n","    'wrinkle_forehead': 1,       # 이마\n","    'wrinkle_glabellus': 2,       # 미간\n","    'chin_sagging' : 8,          # 턱\n","    'l_cheek_pore' : 5,          # 왼쪽 볼\n","    'r_cheek_pore' : 6           # 오른쪽 볼\n","}\n","\n","#################################################################################################\n","# 모델 정의\n","class DenseNet201_VGG19_Ensemble(nn.Module):\n","    def __init__(self, num_classes, drop_out):\n","        super(DenseNet201_VGG19_Ensemble, self).__init__()\n","\n","        # DenseNet201 정의\n","        self.densenet = models.densenet201(weights=DenseNet201_Weights.DEFAULT)\n","        densenet_features = self.densenet.classifier.in_features\n","        self.densenet.classifier = nn.Identity()  # 최종 분류기를 제거하고 특징만 추출\n","\n","        # VGG19 정의\n","        self.vgg = models.vgg19(weights=VGG19_Weights.DEFAULT)\n","        vgg_features = self.vgg.classifier[0].in_features\n","        self.vgg.classifier = nn.Identity()  # 최종 분류기를 제거하고 특징만 추출\n","\n","        # 두 모델의 특징을 결합하는 계층\n","        self.classifier = nn.Sequential(\n","            nn.Linear(densenet_features + vgg_features, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(p=drop_out),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Dropout(p=drop_out),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        # DenseNet201 특징 추출\n","        densenet_features = self.densenet(x)\n","\n","        # VGG19 특징 추출\n","        vgg_features = self.vgg(x)\n","\n","        # 두 특징을 결합\n","        combined_features = torch.cat((densenet_features, vgg_features), dim=1)\n","\n","        # 최종 분류\n","        output = self.classifier(combined_features)\n","        return output\n","###############################################################################\n","# 모델 설정\n","model_settings = {\n","    'pigmentation_forehead': {\n","        'path': '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/yolo/final_model/forehead_pigmentation.pth',\n","        'num_classes': 2,\n","        'dropout_rate': 0.5\n","    },\n","    'pigmentation_cheek_l': {\n","        'path': '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/yolo/final_model/cheek_pigmentation.pth',\n","        'num_classes': 2,\n","        'dropout_rate': 0.5\n","    },\n","    'pigmentation_cheek_r': {\n","        'path': '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/yolo/final_model/cheek_pigmentation.pth',\n","        'num_classes': 2,\n","        'dropout_rate': 0.5\n","    },\n","\n","    'wrinkle_perocular_r': {\n","        'path':  '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/yolo/final_model/persocular_wrinkle.pth',\n","        'num_classes': 2,\n","        'dropout_rate': 0.3\n","    },\n","    'wrinkle_perocular_l': {\n","        'path':   '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/yolo/final_model/persocular_wrinkle.pth',\n","        'num_classes': 2,\n","        'dropout_rate': 0.3\n","    },\n","    'wrinkle_forehead': {\n","        'path': '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/yolo/final_model/forehead_wrinkle.pth',\n","        'num_classes': 2,\n","        'dropout_rate': 0.5\n","    },\n","    'wrinkle_glabellus':{\n","        'path':  '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/yolo/final_model/wrinkle_glabellus.pth',\n","        'num_classes': 2,\n","        'dropout_rate': 0.5\n","    },\n","    'chin_sagging':{\n","        'path':  '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/yolo/final_model/chin_sagging.pt',\n","        'num_classes': 2,\n","        'dropout_rate': 0.5\n","    },\n","    'l_cheek_pore':{\n","        'path':  '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/yolo/final_model/cheek_pore.pt',\n","        'num_classes': 2,\n","        'dropout_rate': 0.5\n","    },\n","    'r_cheek_pore':{\n","        'path':  '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/yolo/final_model/cheek_pore.pt',\n","        'num_classes': 2,\n","        'dropout_rate': 0.5\n","    }\n","}\n","\n","\n","\n","# 모델 로드 및 예측\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","all_results = []\n","for annotation, class_id in model_class_id_map.items():\n","    model_settings_for_annotation = model_settings[annotation]\n","    resnet_model = DenseNet201_VGG19_Ensemble(\n","        num_classes=model_settings_for_annotation['num_classes'],\n","        drop_out=model_settings_for_annotation['dropout_rate']\n","\n","    )\n","    # state_dict를 로드하고 모델에 적용\n","    # state_dict의 키 이름을 변경하여 로드\n","    def rename_state_dict_keys(state_dict, prefix=\"vgg\"):\n","        renamed_state_dict = {}\n","        for key, value in state_dict.items():\n","            if key.startswith(\"vgg19.\"):\n","                new_key = key.replace(\"vgg19.\", f\"{prefix}.\")\n","                renamed_state_dict[new_key] = value\n","            else:\n","                renamed_state_dict[key] = value\n","        return renamed_state_dict\n","\n","# 가중치 로드 및 키 이름 수정\n","    state_dict = torch.load(model_settings_for_annotation['path'], map_location=device)\n","    renamed_state_dict = rename_state_dict_keys(state_dict)\n","    resnet_model.load_state_dict(renamed_state_dict)\n","\n","    resnet_model.to(device).eval()\n","    results_for_annotation = cropped_img(annotation, resnet_model, results, class_id)\n","    all_results.extend(results_for_annotation)\n","#################################################################################\n","\n","\n","\n","# JSON 파일로 저장\n","json_file_path = '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/yolo/detection_results.json'\n","with open(json_file_path, 'w') as f:\n","    json.dump(all_results, f, indent=2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":332,"status":"ok","timestamp":1724916857783,"user":{"displayName":"Entourage_Team2","userId":"16076991921669842388"},"user_tz":-540},"id":"FyadfaDi3XPx","outputId":"6352b008-08bb-4aaf-f7d6-de72bb308de4"},"outputs":[{"output_type":"stream","name":"stdout","text":["[\n","  {\n","    \"class\": \"pigmentation_forehead\",\n","    \"predicted_class\": 0\n","  },\n","  {\n","    \"class\": \"pigmentation_cheek_l\",\n","    \"predicted_class\": 1\n","  },\n","  {\n","    \"class\": \"pigmentation_cheek_r\",\n","    \"predicted_class\": 1\n","  },\n","  {\n","    \"class\": \"wrinkle_perocular_r\",\n","    \"predicted_class\": 1\n","  },\n","  {\n","    \"class\": \"wrinkle_perocular_l\",\n","    \"predicted_class\": 1\n","  },\n","  {\n","    \"class\": \"wrinkle_forehead\",\n","    \"predicted_class\": 1\n","  },\n","  {\n","    \"class\": \"wrinkle_glabellus\",\n","    \"predicted_class\": 0\n","  },\n","  {\n","    \"class\": \"chin_sagging\",\n","    \"predicted_class\": 0\n","  },\n","  {\n","    \"class\": \"l_cheek_pore\",\n","    \"predicted_class\": 1\n","  },\n","  {\n","    \"class\": \"r_cheek_pore\",\n","    \"predicted_class\": 1\n","  }\n","]\n"]}],"source":["import json\n","\n","# JSON 파일을 읽어오는 함수\n","def load_results_from_json(filename):\n","    with open(filename, 'r') as json_file:\n","        results_data = json.load(json_file)\n","    return results_data\n","\n","# JSON 파일 경로\n","json_file_path = '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/yolo/detection_results.json'\n","\n","\n","# JSON 파일 읽기\n","results_data = load_results_from_json(json_file_path)\n","\n","# 결과 출력\n","print(json.dumps(results_data, indent=2))"]},{"cell_type":"code","source":[],"metadata":{"id":"VEsmXz990Qlv"},"execution_count":null,"outputs":[]}]}